# -*- coding: utf-8 -*-
"""ComputerVision_FinalAssessment_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ms_qUpPPJaNNYb52AnWbtsHuS_z7MvqF
"""

#import libraries
import cv2
import time
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib as plt
import matplotlib.pylab as plt
import os
from os.path import isfile, join
import re

#mount from google drive
import io
import requests
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#the directory of the video 
mp4_video = "/content/drive/MyDrive/Colab Notebooks/traffic.mp4"
#variable to store the video 
vid= cv2.VideoCapture(mp4_video)
#create an empty list to store the frames 
col_f = []
#separate each frame of the video 
while(vid.isOpened()):
    #read the frame of the video 
    ret, frame = vid.read()
    if ret == False:
        break
    #store each frame in a list 
    col_f.append(frame)
    
 
vid.release()

#display the columns of the frames
len(col_f)

#display 50th and 51th frame
i = 50

for frame in [i, i+1]:
    plt.imshow(cv2.cvtColor(col_f[frame], cv2.COLOR_BGR2RGB))
    plt.title("frame: "+str(frame))
    plt.show()

#find the noises of the image
edge_cascade_img = cv2.Canny(col_f[50],150,185)
plt.imshow(edge_cascade_img,cmap='gray')
plt.show()

#filter the noises of the image
def filter_noise(imgs):
  no_noise = []
  for i in range(len(imgs)):
    blur = cv2.GaussianBlur(imgs[i],(3,3),cv2.BORDER_DEFAULT)
    no_noise.append(blur)
  return no_noise 

no_noise = filter_noise(col_f)

#display the orginal frame
plt.imshow(cv2.cvtColor(col_f[i], cv2.COLOR_BGR2RGB))

#display the filtered frame
plt.imshow(cv2.cvtColor(no_noise[i], cv2.COLOR_BGR2RGB))

#find the noises of the image
edge_cascade_img = cv2.Canny(no_noise[50],150,185)
plt.imshow(edge_cascade_img,cmap='gray')
plt.show()

plt.imshow(cv2.cvtColor(no_noise[50], cv2.COLOR_BGR2RGB))
plt.show()

for frame in [i, i+1]:
    plt.imshow(cv2.cvtColor(no_noise[frame], cv2.COLOR_BGR2RGB))
    plt.title("frame: "+str(frame))
    plt.show()

#differentiate between the 2 consecutive frames
A = cv2.cvtColor(no_noise[i], cv2.COLOR_BGR2GRAY)
B = cv2.cvtColor(no_noise[i+1], cv2.COLOR_BGR2GRAY)

# plot the image after frame differencing
plt.imshow(cv2.absdiff(B, A), cmap = 'gray')
plt.show()

diff = cv2.absdiff(B, A)

# perform image thresholding
ret, threshold = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)

# plot image after thresholding
plt.imshow(threshold, cmap = 'gray')
plt.title("Image thresholding")
plt.show()

# apply image dilation
k = np.ones((3,3),np.uint8)
dilated = cv2.dilate(threshold,k,iterations = 2)

# plot dilated image
plt.imshow(dilated, cmap = 'gray')
plt.show()

eroded_frame = cv2.erode(dilated,k,2)
#plot the eroded image 
plt.imshow(eroded_frame,cmap='gray')
plt.show()

#plot the line to detect the car
cv2.line(eroded_frame, (0, 20),(256,20),(100, 0, 0))
plt.imshow(eroded_frame)
plt.show()

#find the contours in the image
contours, hierarchy = cv2.findContours(threshold.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)

#find the valid contours
roi = []

for i,cntr in enumerate(contours):
    x,y,w,h = cv2.boundingRect(cntr)
    if (x <= 140) & (y >= 20) & (cv2.contourArea(cntr) >= 25):
        roi.append(cntr)

# count of discovered contours        
len(roi)

#display the image with the valid contours
dmy = col_f[50].copy()

cv2.drawContours(dmy, roi, -1, (127,200,0), 2)
cv2.line(dmy, (0, 20),(256,20),(100, 255, 255))
cv2.rectangle(dmy, (x, y), (x+w, y+h), color = (255, 0, 0), thickness = 2)
plt.imshow(dmy)
plt.show()

# kernel for image dilation
k = np.ones((4,4),np.uint8)

# font style
font = cv2.FONT_HERSHEY_SIMPLEX

# directory to save the ouput frames
pathIn = "/content/drive/MyDrive/Colab Notebooks/In/"

for i in range(len(col_f)-1):
    
    # frame differencing
    grayA = cv2.cvtColor(col_f[i], cv2.COLOR_BGR2GRAY)
    grayB = cv2.cvtColor(col_f[i+1], cv2.COLOR_BGR2GRAY)
    diff_image = cv2.absdiff(grayB, grayA)
    
    # image thresholding
    ret, thresh = cv2.threshold(diff_image, 30, 255, cv2.THRESH_BINARY)
    
    # image dilation
    dilated = cv2.dilate(thresh,k,iterations = 1)
    
    # find contours
    contours, hierarchy = cv2.findContours(dilated.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
    
    # shortlist contours appearing in the detection zone
    valid_cntrs = []
    for cntr in contours:
        x,y,w,h = cv2.boundingRect(cntr)
        if (x <= 140) & (y >= 20) & (cv2.contourArea(cntr) >= 25):
            if (y >= 110) & (cv2.contourArea(cntr) < 40):
                break
            valid_cntrs.append(cntr)
            
    # add contours to original frames
    dmy = col_f[i].copy()
    cv2.drawContours(dmy, valid_cntrs, -1, (127,200,0), 2)
    
    #cv.putText(dmy, "vehicles detected: " + str(len(valid_cntrs)), (55, 15), font, 0.6, (0, 180, 0), 2)
    cv2.line(dmy, (0, 20),(256,20),(100, 255, 255))
    cv2.imwrite(pathIn+str(i)+'.png',dmy)

# specify video name
pathOut = "/content/drive/MyDrive/Colab Notebooks/Out/video2.mp4"

# specify frames per second
fps = 15.0

#create an empty array to store the frame from the images
frame_array = []
files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]

#sort the frames according to the numbers, in ascending order
files.sort(key=lambda f: int(re.sub('\D', '', f)))

for i in range(len(files)):
    filename=pathIn + files[i]
    
    #read frames
    img = cv2.imread(filename)
    height, width, layers = img.shape
    size = (width,height)
    
    #inserting the frames into an image array
    frame_array.append(img)

#display the size of frame of the video
print(size)

#ouput the video to a specific location
out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)

for i in range(len(frame_array)):
    # writing to a image array
    out.write(frame_array[i])

out.release()